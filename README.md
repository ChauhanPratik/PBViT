# PBViT: Patch-Based Vision Transformer for Brain Tumor Detection

This repository contains the full implementation of the **PBViT (Patch-Based Vision Transformer)** model as described in the published IEEE research paper:

> ğŸ“„ [PBVit: A Patch-Based Vision Transformer for Enhanced Brain Tumor Detection](https://ieeexplore.ieee.org/abstract/document/10811909), IEEE Access, 2024

---

## ğŸ“ Repository Structure

```bash
PBViT/
â”œâ”€â”€ preprocessing/
â”‚   â”œâ”€â”€ 1_dataset_preparation_pbvit.ipynb       # Raw image handling and patch generation
â”‚   â””â”€â”€ 2_train_test_split_pbvit.ipynb          # Stratified split of dataset into train/test
â”œâ”€â”€ training/
â”‚   â””â”€â”€ 3_Training.ipynb                         # Full training pipeline with evaluation
â””â”€â”€ README.md
```

## ğŸš€ Model Overview
PBViT is a lightweight and accurate Transformer-based model optimized for medical imaging tasks. Instead of operating on full-resolution brain scans, PBViT processes fixed-size image patches, capturing localized features crucial for tumor localization and classification.

## ğŸ§  Key Features
- ğŸ§© Patch-based processing for improved granularity
- ğŸ¯ Transformer encoder to model spatial dependencies
- ğŸ”¬ Targeted for brain tumor detection using MRI slices
- ğŸ“Š Reproducible training pipeline with visual metrics and evaluation

## ğŸ“š Citation
```bash
@article{chauhan2024pbvit,
  title={PBVit: A Patch-Based Vision Transformer for Enhanced Brain Tumor Detection},
  author={Chauhan, Pratikkumar and Lunagaria, Munindra and Verma, Deepak Kumar and Vaghela, Krunal and Tejani, Ganshyam and Sharma, Sunil and Khan, Ahmad Raza},
  journal={IEEE Access},
  year={2024},
  publisher={IEEE}
}
```
