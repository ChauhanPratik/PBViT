{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXdEvUTE21PC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIgFoWex7zPm",
        "outputId": "0fc7100e-9c64-42b5-c672-8870932138f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04WehUB73a0h"
      },
      "outputs": [],
      "source": [
        "coco_dir = '/content/drive/MyDrive/Brain Tumor/coco'\n",
        "images_dir = os.path.join(coco_dir, 'images')\n",
        "annotations_file = os.path.join(coco_dir, 'annotations.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcAJHbW83ciV"
      },
      "outputs": [],
      "source": [
        "TRAIN_PERCENT = 0.7\n",
        "VAL_PERCENT = 0.1\n",
        "TEST_PERCENT = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JzSRGJFC7ir2",
        "outputId": "ec71e6ea-e974-4218-f52d-f10313e84509"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train set created with 536 images.\n",
            "Validation set created with 76 images.\n",
            "Test set created with 154 images.\n"
          ]
        }
      ],
      "source": [
        "def split_dataset(images_dir, annotations_file):\n",
        "    with open(annotations_file, 'r') as f:\n",
        "        coco_data = json.load(f)\n",
        "\n",
        "    random.shuffle(coco_data['images'])\n",
        "\n",
        "    num_images = len(coco_data['images'])\n",
        "    num_train = int(num_images * TRAIN_PERCENT)\n",
        "    num_val = int(num_images * VAL_PERCENT)\n",
        "    num_test = num_images - num_train - num_val\n",
        "\n",
        "    train_images = coco_data['images'][:num_train]\n",
        "    val_images = coco_data['images'][num_train:num_train+num_val]\n",
        "    test_images = coco_data['images'][num_train+num_val:]\n",
        "\n",
        "    train_dir = os.path.join(coco_dir, 'train')\n",
        "    val_dir = os.path.join(coco_dir, 'valid')\n",
        "    test_dir = os.path.join(coco_dir, 'test')\n",
        "    os.makedirs(train_dir, exist_ok=True)\n",
        "    os.makedirs(val_dir, exist_ok=True)\n",
        "    os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "    def move_images_and_update_annotations(image_list, target_dir, subset_name):\n",
        "        subset_annotations = {\n",
        "            \"info\": coco_data[\"info\"],\n",
        "            \"licenses\": coco_data[\"licenses\"],\n",
        "            \"images\": [],\n",
        "            \"annotations\": [],\n",
        "            \"categories\": coco_data[\"categories\"]\n",
        "        }\n",
        "        for image_info in image_list:\n",
        "            image_filename = image_info['file_name']\n",
        "            src_image_path = os.path.join(images_dir, image_filename)\n",
        "            dst_image_path = os.path.join(target_dir, image_filename)\n",
        "            shutil.copyfile(src_image_path, dst_image_path)\n",
        "\n",
        "            subset_annotations['images'].append(image_info)\n",
        "            image_id = image_info['id']\n",
        "            annotations = [ann for ann in coco_data['annotations'] if ann['image_id'] == image_id]\n",
        "            subset_annotations['annotations'].extend(annotations)\n",
        "\n",
        "        subset_annotations_file = os.path.join(target_dir, f'annotations.json')\n",
        "        with open(subset_annotations_file, 'w') as f:\n",
        "            json.dump(subset_annotations, f)\n",
        "\n",
        "        print(f\"{subset_name} set created with {len(image_list)} images.\")\n",
        "\n",
        "    move_images_and_update_annotations(train_images, train_dir, \"Train\")\n",
        "    move_images_and_update_annotations(val_images, val_dir, \"Validation\")\n",
        "    move_images_and_update_annotations(test_images, test_dir, \"Test\")\n",
        "\n",
        "\n",
        "split_dataset(images_dir, annotations_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esC0mFh-L4wK"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNLUW_Tyrt6P"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}